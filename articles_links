Theory Book on Statistical Learning
https://web.stanford.edu/~hastie/Papers/ESLII.pdf

Fine-tuning Classifier:
https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65
https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c


Classifier Evaluation Metrics:
https://medium.com/@george.drakos62/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-3-classification-3eac420ec991
https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c

Logistic Regression (in-depth basics and theory):
https://towardsdatascience.com/logit-of-logistic-regression-understanding-the-fundamentals-f384152a33d1

Hyperparameter tuning (different forms of classifiers):
https://github.com/ImadDabbura/blog-posts/blob/master/posts_md/Pedicting_Employee_Turnover.md

VotingClassifier (compare different algorithms):
https://imaddabbura.github.io/post/pred-loan-repayment/

EV (Explained Visually):
http://setosa.io/ev/

Bayes Theorem Explanation: 
http://yudkowsky.net/rational/bayes

Normalization / Standardization:
Cheatsheet: https://docs.google.com/spreadsheets/d/1woVi7wq13628HJ-tN6ApaRGVZ85OdmHsDBKLAf5ylaQ/edit#gid=0 
Article: https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02
Article: http://sebastianraschka.com/Articles/2014_about_feature_scaling.html
https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf

Forecasting:
https://www.datasciencecentral.com/profiles/blogs/modern-approaches-for-sales-predictive-analytics-1

Cosine and Euclidian Distance:
https://cmry.github.io/notes/euclidean-v-cosine

SMOTE vs ADYSYN:
https://www.kaggle.com/residentmario/oversampling-with-smote-and-adasyn

SVM:
https://medium.com/@zachary.bedell/support-vector-machines-explained-73f4ec363f13

GradientBoosting:
https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4

Clustering (Gaussian Mixture Models):
https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e

Cost-sensitive learning:
https://towardsdatascience.com/fraud-detection-with-cost-sensitive-machine-learning-24b8760d35d9

Tree vs. Forest:
https://towardsdatascience.com/why-random-forests-outperform-decision-trees-1b0f175a0b5

NLP:
https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e
https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a
https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff
https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f
https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b



Python Programming ():

Namespacing in Python:
https://medium.com/better-programming/namespacing-with-python-79574d125564

Demystifying lambda:
https://medium.com/better-programming/how-to-use-lambda-expressions-in-python-a96330b513d4
https://levelup.gitconnected.com/a-practical-introduction-to-python-lambda-functions-3b4a0702b6a1

List comprehension:
https://levelup.gitconnected.com/3-python-list-comprehension-tricks-you-might-not-know-yet-5891d904ee76

Method chaining:
https://tomaugspurger.github.io/method-chaining

Map, Reduce, Filter:
https://medium.com/better-programming/how-to-start-using-map-filter-and-reduce-e01edba0d81


